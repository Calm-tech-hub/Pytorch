{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1.所有表示从键到数据样本映射的数据集都应该继承它。所有子类都应该重写__getitem__方法,\\n支持根据给定的键获取一个数据样本。子类也可以选择性地重写__len__方法,返回数据集合大小\\n许多torch.utils.data.Sampler的实现以及torch.utils.data.DataLoader的默认选项都期望该方法返回数据集的大小。\\n\\n2.(注意):默认情况下,torch.utils.data.DataLoader会构建一个产生整数索引的索引采样器。\\n为了使其与具有非整数索引 / 键的映射样式数据集一起工作，必须提供一个自定义采样器。\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGeneric\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34mr\"\"\"An abstract class representing a :class:`Dataset`.\n",
      "\n",
      "    All datasets that represent a map from keys to data samples should subclass\n",
      "    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "    data sample for a given key. Subclasses could also optionally overwrite\n",
      "    :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      "    :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "    of :class:`~torch.utils.data.DataLoader`.\n",
      "\n",
      "    .. note::\n",
      "      :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      "      sampler that yields integral indices.  To make it work with a map-style\n",
      "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Dataset[T_co]'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'ConcatDataset[T_co]'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# No `def __len__(self)` default?\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# in pytorch/torch/utils/data/sampler.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataset.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     IterableDataset, TensorDataset, ConcatDataset, Subset, MapDataPipe\n"
     ]
    }
   ],
   "source": [
    "Dataset??\n",
    "'''\n",
    "1.所有表示从键到数据样本映射的数据集都应该继承它。所有子类都应该重写__getitem__方法,\n",
    "支持根据给定的键获取一个数据样本。子类也可以选择性地重写__len__方法,返回数据集合大小\n",
    "许多torch.utils.data.Sampler的实现以及torch.utils.data.DataLoader的默认选项都期望该方法返回数据集的大小。\n",
    "\n",
    "2.(注意):默认情况下,torch.utils.data.DataLoader会构建一个产生整数索引的索引采样器。\n",
    "为了使其与具有非整数索引 / 键的映射样式数据集一起工作，必须提供一个自定义采样器。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.path = os.path.join(self.root_dir,self.label_dir)\n",
    "        self.img_path = os.listdir(self.path)\n",
    "\n",
    "    def __getitem__(self,idx):#idx:编号\n",
    "        img_name = self.img_path[idx]\n",
    "        img_item_path = os.path.join(self.root_dir,self.label_dir,img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir\n",
    "        return img,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "\n",
    "root_dir = r\"hymenoptera_data\\train\"\n",
    "ants_label_dir = \"ants\"\n",
    "ants_dataset = MyData(root_dir,ants_label_dir)\n",
    "\n",
    "img,label = ants_dataset.__getitem__(1)\n",
    "img.show() \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.path = os.path.join(self.root_dir,self.label_dir)\n",
    "        self.img_path = os.listdir(self.path)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.img_path[idx]\n",
    "        img_item_path = os.path.join(self.root_dir,self.label_dir,img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir\n",
    "        return img,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "root_dir = r\"hymenoptera_data\\train\"\n",
    "ants_label_dir = \"ants\"\n",
    "ants_dataset = MyData(root_dir,ants_label_dir)\n",
    "img,label = ants_dataset[0]\n",
    "img.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.path = os.path.join(self.root_dir,self.label_dir)\n",
    "        self.img_path = os.listdir(self.path)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.img_path[idx]\n",
    "        img_path_dir = os.path.join(self.root_dir,self.label_dir,img_name)\n",
    "        img = Image.open(img_path_dir)\n",
    "        label = self.label_dir\n",
    "        return img,label\n",
    "    \n",
    "root_dir = r\"hymenoptera_data\\train\"\n",
    "bees_label_dir = \"bees\"\n",
    "bees_dataset = MyData(root_dir,bees_label_dir)\n",
    "img,label = bees_dataset.__getitem__(1)\n",
    "img.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bees_label_dir = \"bees\"\n",
    "bees_dataset = MyData(root_dir,bees_label_dir)\n",
    "img,_=bees_dataset.__getitem__(0)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "121\n",
      "245\n"
     ]
    }
   ],
   "source": [
    "train_data = ants_dataset + bees_dataset\n",
    "print(len(ants_dataset))\n",
    "print(len(bees_dataset))\n",
    "print(len(train_data))\n",
    "img,label = train_data[123]\n",
    "img.show()\n",
    "\n",
    "img,label = train_data[124]\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 512)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1.获取图片地址\n",
    "2.img = Image.open()\n",
    "3.img.show()\n",
    "'''\n",
    "img_path = r\"C:\\Users\\86138\\Desktop\\Pytorch learn\\hymenoptera_data\\train\\ants\\0013035.jpg\"\n",
    "img = Image.open(img_path)\n",
    "print(img.size)\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0013035.jpg\n",
      "1030023514_aad5c608f9.jpg\n",
      "1095476100_3906d8afde.jpg\n"
     ]
    }
   ],
   "source": [
    "dir_path = r\"C:\\Users\\86138\\Desktop\\Pytorch learn\\hymenoptera_data\\train\\ants\"\n",
    "img_path_list = os.listdir(dir_path)\n",
    "for i in range (3):\n",
    "    print(img_path_list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0013035.jpg', '1030023514_aad5c608f9.jpg', '1095476100_3906d8afde.jpg', '1099452230_d1949d3250.jpg', '116570827_e9c126745d.jpg', '1225872729_6f0856588f.jpg', '1262877379_64fcada201.jpg', '1269756697_0bce92cdab.jpg', '1286984635_5119e80de1.jpg', '132478121_2a430adea2.jpg', '1360291657_dc248c5eea.jpg', '1368913450_e146e2fb6d.jpg', '1473187633_63ccaacea6.jpg', '148715752_302c84f5a4.jpg', '1489674356_09d48dde0a.jpg', '149244013_c529578289.jpg', '150801003_3390b73135.jpg', '150801171_cd86f17ed8.jpg', '154124431_65460430f2.jpg', '162603798_40b51f1654.jpg', '1660097129_384bf54490.jpg', '167890289_dd5ba923f3.jpg', '1693954099_46d4c20605.jpg', '175998972.jpg', '178538489_bec7649292.jpg', '1804095607_0341701e1c.jpg', '1808777855_2a895621d7.jpg', '188552436_605cc9b36b.jpg', '1917341202_d00a7f9af5.jpg', '1924473702_daa9aacdbe.jpg', '196057951_63bf063b92.jpg', '196757565_326437f5fe.jpg', '201558278_fe4caecc76.jpg', '201790779_527f4c0168.jpg', '2019439677_2db655d361.jpg', '207947948_3ab29d7207.jpg', '20935278_9190345f6b.jpg', '224655713_3956f7d39a.jpg', '2265824718_2c96f485da.jpg', '2265825502_fff99cfd2d.jpg', '226951206_d6bf946504.jpg', '2278278459_6b99605e50.jpg', '2288450226_a6e96e8fdf.jpg', '2288481644_83ff7e4572.jpg', '2292213964_ca51ce4bef.jpg', '24335309_c5ea483bb8.jpg', '245647475_9523dfd13e.jpg', '255434217_1b2b3fe0a4.jpg', '258217966_d9d90d18d3.jpg', '275429470_b2d7d9290b.jpg', '28847243_e79fe052cd.jpg', '318052216_84dff3f98a.jpg', '334167043_cbd1adaeb9.jpg', '339670531_94b75ae47a.jpg', '342438950_a3da61deab.jpg', '36439863_0bec9f554f.jpg', '374435068_7eee412ec4.jpg', '382971067_0bfd33afe0.jpg', '384191229_5779cf591b.jpg', '386190770_672743c9a7.jpg', '392382602_1b7bed32fa.jpg', '403746349_71384f5b58.jpg', '408393566_b5b694119b.jpg', '424119020_6d57481dab.jpg', '424873399_47658a91fb.jpg', '450057712_771b3bfc91.jpg', '45472593_bfd624f8dc.jpg', '459694881_ac657d3187.jpg', '460372577_f2f6a8c9fc.jpg', '460874319_0a45ab4d05.jpg', '466430434_4000737de9.jpg', '470127037_513711fd21.jpg', '474806473_ca6caab245.jpg', '475961153_b8c13fd405.jpg', '484293231_e53cfc0c89.jpg', '49375974_e28ba6f17e.jpg', '506249802_207cd979b4.jpg', '506249836_717b73f540.jpg', '512164029_c0a66b8498.jpg', '512863248_43c8ce579b.jpg', '518773929_734dbc5ff4.jpg', '522163566_fec115ca66.jpg', '522415432_2218f34bf8.jpg', '531979952_bde12b3bc0.jpg', '533848102_70a85ad6dd.jpg', '535522953_308353a07c.jpg', '540889389_48bb588b21.jpg', '541630764_dbd285d63c.jpg', '543417860_b14237f569.jpg', '560966032_988f4d7bc4.jpg', '5650366_e22b7e1065.jpg', '6240329_72c01e663e.jpg', '6240338_93729615ec.jpg', '649026570_e58656104b.jpg', '662541407_ff8db781e7.jpg', '67270775_e9fdf77e9d.jpg', '6743948_2b8c096dda.jpg', '684133190_35b62c0c1d.jpg', '69639610_95e0de17aa.jpg', '707895295_009cf23188.jpg', '7759525_1363d24e88.jpg', '795000156_a9900a4a71.jpg', '822537660_caf4ba5514.jpg', '82852639_52b7f7f5e3.jpg', '841049277_b28e58ad05.jpg', '886401651_f878e888cd.jpg', '892108839_f1aad4ca46.jpg', '938946700_ca1c669085.jpg', '957233405_25c1d1187b.jpg', '9715481_b3cb4114ff.jpg', '998118368_6ac1d91f81.jpg', 'ant photos.jpg', 'Ant_1.jpg', 'army-ants-red-picture.jpg', 'formica.jpeg', 'hormiga_co_por.jpg', 'imageNotFound.gif', 'kurokusa.jpg', 'MehdiabadiAnt2_600.jpg', 'Nepenthes_rafflesiana_ant.jpg', 'swiss-army-ant.jpg', 'termite-vs-ant.jpg', 'trap-jaw-ant-insect-bg.jpg', 'VietnameseAntMimicSpider.jpg']\n",
      "hymenoptera_data\\train\\ants\\0013035.jpg\n"
     ]
    }
   ],
   "source": [
    "root_dir = r\"hymenoptera_data\\train\"\n",
    "label_dir = \"ants\"\n",
    "path = os.path.join(root_dir,label_dir)\n",
    "img_path = os.listdir(path)#该文件下的文件名列表\n",
    "print(img_path)\n",
    "img_name = img_path[0]\n",
    "img_item_path = os.path.join(root_dir,label_dir,img_name)\n",
    "print(img_item_path)\n",
    "img = Image.open(img_item_path)\n",
    "img.show()  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
